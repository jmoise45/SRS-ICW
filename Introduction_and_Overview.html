<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta content="en-us" http-equiv="Content-Language" />
<meta content="text/html; charset=utf-8" http-equiv="Content-Type" />
<title>Performance Calculation for M</title> <script type="text/javascript" src="Script/jquery.js"></script> 

<link rel="stylesheet" type="text/css" href="Styles/shadowbox.css">
<script type="text/javascript" src="Script/shadowbox.js"></script>
<link rel="stylesheet" type="text/css" href="Styles/styles.css">
<script type="text/javascript" src="Script/custom_script.js"></script> 

<script type="text/javascript">
		
Shadowbox.init();
	
</script>

</head>
	<body>

		<a name="Sec1.1"></a>
		</p><h3>1.1. Introduction and Overview </h3>

		</p>
		<p align="JUSTIFY">
			Computers are comprised of software and hardware.  In
			previous programming classes, we studied how high-level software
			could be used to drive computer hardware.  In this course, we
			concentrate on the development of hardware, and show how it supports
			the execution of software at a low level.

		</p><h4>1.1.1. Course Overview and Objectives</h4>

		<p align="JUSTIFY">
			This course is designed to convey some "big ideas"
			about computing, with enough low-level support and knowledge to
			understand the practical uses and implications of these ideas, which
			are:

		</p>
		<ol>
			<p></p>
			<li>
				<p align="JUSTIFY">
					<i>Five components of a computer</i> -
					memory, datapath, control, input, and output, which are used in
					modern digital computing machines.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Data can be anything</i> - integers,
					floating point, characters, bitstream.  The actual values and use
					of data are determined by the program (software) running on the
					computer.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Stored program</i> - instructions in
					memory can be thought of as data.  They can be accessed randomly
					or sequentially, and can be input or output (read or written in
					and out, respectively) to increase memory utilization.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Principle of locality</i> - in a given
					(small) time slice, most memory I/O is done in a small cluster of
					addresses. The phenomenon of locality supports scheduling and
					prediction of memory accesses, which enables devices like caches
					to work efficiently.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Parallelism</i> - many processors can
					work together efficiently to solve a problem, which increases
					performance and decreases execution time.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Composition</i> - allows us to build
					complex systems by first starting with small components, then
					building larger components from the smaller ones.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Abstraction</i> - supports the naming
					and description of complex, low-level system objects with
					high-level constructs that are more easily understood by humans.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Compilation versus Interpretation</i> -
					a key issue when considering computer language implementation and
					use.  Compilation uses software to directly produce executable
					code that can be optimized to run on a given machine.
					Interpretation attempts to execute source code by translating it
					into executable code just prior to execution.  Because
					optimizations are hard to perform dynamically, reduced system
					performance tends to result.

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Principles and Pitfalls of Performance
					Measurement</i> - know <b>what</b> you are measuring, <b>where</b>
					and <b>how</b> to measure it, <b>when</b> a given measurement (or <i>metric</i>) is useful, and <b>why</b> a given metric works (or
					doesn't work) in a given situation.
				</p>
			</li>
		</ol>

		<h4>1.1.2. Course Overview and Objectives</h4>

		In order to convey this information, we have a highly detailed <a href="http://www.cise.ufl.edu/~mssz/CompOrg/req-text.html">textbook</a>, from which the following topics
		will be drawn:

		<ul>
			<p></p>
			<li>
				<p align="JUSTIFY">
					<i>Abstraction and Technology</i> - Chapter 1

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Performance Measurement</i> - Chapter 2

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Instruction Set Architecture</i> - Chapter 3

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Arithmetic and ALU Design</i> - Chapter 4

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>CPU Design and Execution</i> - Chapter 5

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Pipelining for Increased Performance</i> - Chapter 6

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>Memory: Cache, Main, Virtual</i> - Chapter 7

				</p><p></p>
			</li>
			<li>
				<p align="JUSTIFY">
					<i>I/O Devices and Protocols</i> - Chapter 8
				</p>
			</li>
		</ul>

		<h4>1.1.3. Origins and History</h4>

		<p align="JUSTIFY">
			In this section, we present a brief overview of
			computer history.  Additional information can be found at
			<a href="http://www.digitalcentury.com/encyclo/update/comp_hd.html"> The Digital Century link</a>.

		</p>
		<p align="JUSTIFY">
			In this historical epoch, computers were first
			developed by the Egyptians, who had the <a href="http://www.ee.ryerson.ca:8080/~elf/abacus/">abacus</a> and <a href="http://physics.nist.gov/GenInt/Time/early.html">shadow
			clocks</a>. In the pre-industrial era, mechanical calculators were
			developed by Pascal and Leibniz.  During the Industrial Revolution,
			mechanical computers were envisioned, and parts of such machines were
			prototyped, by Charles Babbage.  These computers were not constructed
			in their entirety, due to size, weight, and power requirements that
			could not be satisfied by the technology of the day. An interesting
			overview of early mechanical computers is given in
			<a href="http://www.scri.fsu.edu/~odyssey/cyberkids/computers/history/"> this link</a>.

		</p>
		<p align="JUSTIFY">
			With the discovery of electricity, electronic
			tabulating machines were developed by Herman Hollerith, whose company
			was purchased by Thomas Watson, founder of the International Business
			Machines Corporation.  Throughout the 1920s and 1930s, IBM marketed a
			variety of tabulating machines driven by electrified keyboards and
			having a variety of printers.  Although unsophisticated, this type of
			hardware helped the business community become accustomed to the idea
			of machine-assisted inventory, payroll, and shipping.  Additionally,
			the hardware developed by IBM was modified for use in its early
			computers.  Thus, it could be said that the era of electro-mechanical
			tabulating machines in some ways prepared society for the advent of
			digital computers.

		</p>
		<p align="JUSTIFY">
			The advent of World War II increased the demand for
			more accurate calculations.  Rooms full of humans were employed in
			computing artillery trajectories, and the result was unacceptable
			error.  A variety of computing research projects were undertaken at
			Princeton University, Harvard University, and the University of
			Pennsylvania.  These resulted in room-size computers such as the
			Mark-I through Mark-IV, and the ENIAC, all of which used vacuum tubes.
			The vacuum tube machines were erroneous (tubes burned out or their
			response drifted frequently), power-intensive, slow (less than 10,000
			integer multiplications per second), and hard to program, but provided
			a useful testbed for basic computer concepts.

		</p>
		<p align="JUSTIFY">
			After WWII, the business community was slow to accept
			computers because of their cost, size, weight, power consumption, and the
			cost of maintaining them (including programmer salaries).  However,
			the Defense Department funded computer research during the early years
			of the Cold War, from which resulted the second generation of computers.
			These machines used transistors instead of vacuum tubes, and were
			smaller, less power-consumptive, and easier to use.  Business firms
			became more interested in computing, and IBM started to manufacture
			business and scientific computers (4000 and 7000 series, respectively).

		</p>
		<p align="JUSTIFY">
			In the 1960s, transistors were integrated first on
			small circuit boards, then etched on wafers called <i>integrated
			circuits</i>.  These were much smaller than the second-generation
			computer circuits, and predictably consumed less power, took
			up less space, and were easier to repair (or replace).  In the
			1960s, many electronics companies were in business that are no longer
			building digital computers today - General Electric, RCA, Honeywell,
			and Burroughs, to name but a few.  IBM's System/360 was the first
			general-purpose computer to support both business and scientific
			calculations, and had a number of operating system features that
			were novel for its day, including upward compatibility of software,
			programmability of the operating system through a (dreadful) language
			called OS/JCL, as well as support for numerous programming languages.

		</p>
		<p align="JUSTIFY">
			The 1970s saw the advent of much faster and more
			capable integrated circuits, which made computers smaller and faster.
			IBM's System/370 was the workhorse mainframe series of the era, but was
			challenged by similar architectures, such as those produced by the
			Ahmdahl Corporation.  In the 1970s, two important trends developed in
			addition to mainframe computing.  First, the supercomputer was
			developed largely due to the efforts of Seymour Cray, who pioneered
			high-performance computing in the 1960s with the CDC6600 that he
			developed for Control Data Corporation.  Second, the minicomputer was
			developed by Digital Equipment Corporation (DEC), whose PDP series of
			machines was the first general-purpose computer that small
			universities or research laboratories could afford.  A third trend
			that went almost unnoticed, was the gradual emergence of personal
			computers, which were initially the domain of hobbyists.  From these early
			beginnings came the Apple-II, the world's first affordable, workable
			personal computer that could be operated in some ways like its
			larger ancestors (mainframe or the minicomputer).

		</p>
		<p align="JUSTIFY">
			In the 1980s, integrated circuits gave way to very
			large scale integrated (VLSI) circuit technology, which eventually
			packed millions of transistors onto a single chip.  This comprised the
			fourth generation of computing machine technology.  As a result,
			personal computers became smaller and faster, posing a challenge to
			the minicomputer.  The use of VLSI technology enabled companies like
			DEC to compete with the mainframe market by developing
			superminicomputers.  On the personal computer side of the market, IBM
			introduced the IBM/PC in 1980, which revolutionized the desktop by
			providing a common, open architecture.  A young fellow, who combined
			ideas from DEC's VMS operating system and the emerging UNIX operating
			system, headed a company that was chosen to write the first extensible
			PC operating system - MS-DOS.  The rest, as they say, is history -
			Bill Gates and Microsoft rose with IBM and its processor developer
			Intel to become the dominant players in a multi-billion-dollar
			industry, which eventually eclipsed the mainframe market and consigned
			minicomputers, superminicomputers, and microcomputers to the dustbin
			of history (for all but the most highly customized applications).

		</p>
		<p align="JUSTIFY">
			The 1990s saw the emergence of distributed or
			networked computing and the continued proliferation of personal
			computers.  Another development of the 1990s was mobile computing,
			which could become the dominant paradigm for personal computing in the
			first decade of the new millenium.  On the supercomputer front,
			massively parallel machines were developed to become more practical,
			easier to program, and small enough for a mid-sized university to
			purchase for research or teaching purposes.  Parallel computer
			technology continues to grow, supported in part by ever-smaller
			integrated circuit components and more user-friendly software.
			Distributed technology continues to proliferate both in computing and
			communication.  The Internet and World-Wide Web have unified these
			paradigms to become the dominant platforms for the computerized
			dissemination of knowledge.

		</p>
		<p align="JUSTIFY">
			If you would like to read more, check out the <a href="http://www.hitmill.com/computers/computerhx1.html">Hitmill
			History of Computers Website</a>.  For a comprehensive trip through
			computer history, visit the <a href="http://www.computerhistory.org/">Computer History Museum</a>.

	</body>
</html>

